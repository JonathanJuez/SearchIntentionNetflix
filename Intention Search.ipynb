{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import nltk, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>João Miguel, Bianca Comparato, Michel Gomes, R...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>August 14, 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>4 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Sci-Fi &amp;...</td>\n",
       "      <td>In a future where the elite inhabit an island ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>7:19</td>\n",
       "      <td>Jorge Michel Grau</td>\n",
       "      <td>Demián Bichir, Héctor Bonilla, Oscar Serrano, ...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>December 23, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>93 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>After a devastating earthquake hits Mexico Cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Movie</td>\n",
       "      <td>23:59</td>\n",
       "      <td>Gilbert Chan</td>\n",
       "      <td>Tedd Chan, Stella Chung, Henley Hii, Lawrence ...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>December 20, 2018</td>\n",
       "      <td>2011</td>\n",
       "      <td>R</td>\n",
       "      <td>78 min</td>\n",
       "      <td>Horror Movies, International Movies</td>\n",
       "      <td>When an army recruit is found dead, his fellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>9</td>\n",
       "      <td>Shane Acker</td>\n",
       "      <td>Elijah Wood, John C. Reilly, Jennifer Connelly...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>2009</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>80 min</td>\n",
       "      <td>Action &amp; Adventure, Independent Movies, Sci-Fi...</td>\n",
       "      <td>In a postapocalyptic world, rag-doll robots hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>Movie</td>\n",
       "      <td>21</td>\n",
       "      <td>Robert Luketic</td>\n",
       "      <td>Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...</td>\n",
       "      <td>United States</td>\n",
       "      <td>January 1, 2020</td>\n",
       "      <td>2008</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>123 min</td>\n",
       "      <td>Dramas</td>\n",
       "      <td>A brilliant group of students become card-coun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type  title           director  \\\n",
       "0      s1  TV Show     3%                NaN   \n",
       "1      s2    Movie   7:19  Jorge Michel Grau   \n",
       "2      s3    Movie  23:59       Gilbert Chan   \n",
       "3      s4    Movie      9        Shane Acker   \n",
       "4      s5    Movie     21     Robert Luketic   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0  João Miguel, Bianca Comparato, Michel Gomes, R...         Brazil   \n",
       "1  Demián Bichir, Héctor Bonilla, Oscar Serrano, ...         Mexico   \n",
       "2  Tedd Chan, Stella Chung, Henley Hii, Lawrence ...      Singapore   \n",
       "3  Elijah Wood, John C. Reilly, Jennifer Connelly...  United States   \n",
       "4  Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...  United States   \n",
       "\n",
       "          date_added  release_year rating   duration  \\\n",
       "0    August 14, 2020          2020  TV-MA  4 Seasons   \n",
       "1  December 23, 2016          2016  TV-MA     93 min   \n",
       "2  December 20, 2018          2011      R     78 min   \n",
       "3  November 16, 2017          2009  PG-13     80 min   \n",
       "4    January 1, 2020          2008  PG-13    123 min   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0  International TV Shows, TV Dramas, TV Sci-Fi &...   \n",
       "1                       Dramas, International Movies   \n",
       "2                Horror Movies, International Movies   \n",
       "3  Action & Adventure, Independent Movies, Sci-Fi...   \n",
       "4                                             Dramas   \n",
       "\n",
       "                                         description  \n",
       "0  In a future where the elite inhabit an island ...  \n",
       "1  After a devastating earthquake hits Mexico Cit...  \n",
       "2  When an army recruit is found dead, his fellow...  \n",
       "3  In a postapocalyptic world, rag-doll robots hi...  \n",
       "4  A brilliant group of students become card-coun...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./netflix_titles.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_input,column_name,language=\"english\",tolower=True, html_tags=True, stemming = False,stop_words=False):\n",
    "    \"\"\" Limpieza de datos,se remueven caracteres especiales,limpieza de tags de  HTML\n",
    "        se convierte a munisculas el texto,stemming de texto, se retiras stopwords\n",
    "        se elimina doble espacio\"\"\"\n",
    "     \n",
    "    stemmer_preprocces = SnowballStemmer(language=language)\n",
    "    stop=set(stopwords.words(language))\n",
    "    \n",
    "       \n",
    "    #remove special characters\n",
    "    temp = data_input[column_name].copy()\n",
    "\n",
    "    #elimina carcateres especiales y los convierte en string\n",
    "    temp = temp.apply(lambda x: re.sub(\"[^A-Za-z0-9-\\s]+\",\"\",str(x))) \n",
    "           \n",
    "    #clean HTML tags\n",
    "     # re sub re compile extraera las etiquetas <> las reemplazara por un espacio en blanco y se las asignara a x \n",
    "    if html_tags: temp = temp.apply( lambda x: re.sub(re.compile('<.*?>'), '', x) )\n",
    "         \n",
    "    #tolower todo en minusculas\n",
    "    if tolower: temp =temp.apply(lambda x: str(x).lower())     \n",
    "    \n",
    "    #stemming\n",
    "    #reducira las palabras a su origen reduciendo la dimension de la palabra\n",
    "    ##extraera solo los vocablos o prefijos\n",
    "    if stemming: temp = temp.apply( lambda x: ' '.join([stemmer_preprocces.stem(x_i) for x_i in x.split(' ')]) )\n",
    "                \n",
    "    #remove stopwords\n",
    "    if stop_words: temp = temp.apply( lambda x: ' '.join([y for y in x.split(' ') if y not in stop]) )\n",
    "        \n",
    "    #remove double space\n",
    "    result = temp.apply(lambda x: re.sub(\"\\s\\s+\" , \" \", x))   \n",
    "         \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion coseno de similitud\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "    return np.dot(vector1, vector2) / (np.sqrt(np.sum(vector1*2)) * np.sqrt(np.sum(vector2*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvp_recommender(user_input):\n",
    "    df_sample_title = pd.DataFrame([user_input])\n",
    "\n",
    "    preprocessed_sample = preprocess(df_sample_title,\n",
    "                                       column_name=[0],\\\n",
    "                                       language='english',\\\n",
    "                                       html_tags=False,\\\n",
    "                                       stemming=True,\\\n",
    "                                       stop_words = True)\n",
    "    \n",
    "     #devuelve un vector con una distancia como array para preprocessed sample\n",
    "    bow_sample = name_bow_vectorizer.transform(preprocessed_sample).toarray()\n",
    "    \n",
    "    #se almacenara j es [0 ]y coseno de similitud [1]\n",
    "    temp_similarity = []\n",
    "    \n",
    "    for j in range(0, name_bow_tfidf.shape[0]): \n",
    "        temp_similarity.append([j, cosine_similarity(bow_sample, name_bow_tfidf.toarray()[j]) [0]])\n",
    "        #creara dos columnas una con los indices y otra con el coseno de similitud\n",
    "        #[0] regresara solo un numero \n",
    "\n",
    "    #valores mas altos de similitud\n",
    "    similar_courses = pd.DataFrame(temp_similarity).sort_values(by=[1],ascending=False)\n",
    "    \n",
    "    #similitudes mas altas\n",
    "    similar_coursesl = similar_courses.loc[similar_courses[1]>0].head(5)#regresara las 5 primeras\n",
    "    \n",
    "    #Matriz de resultados concatenados con similitudes\n",
    "    result=similar_coursesl.merge(data['title'],left_on=0,right_index=True, how='left')\n",
    "             \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se llamara la funcion preprocess y se le aplicaran las funciones definidas en ella\n",
    "preprocessed_summary= preprocess(data, column_name='description', language='english',html_tags=False,\n",
    "                                   stemming=True, stop_words = True)\n",
    "\n",
    "#norm puede ser l1 o l2, ngramas de 1 a 2, genera una matriz de entidades de TF-idf \n",
    "name_bow_vectorizer = TfidfVectorizer(norm=\"l2\", analyzer='word', ngram_range=(1,2), max_features = 500)\n",
    "\n",
    "#se aplica funcion a los datos procesados\n",
    "name_bow_tfidf = name_bow_vectorizer.fit_transform(preprocessed_summary) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb5bec4620a4b7c8df46be10a0f63c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='war nations', description='user_input'), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.mvp_recommender(user_input)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(mvp_recommender, user_input='war nations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
